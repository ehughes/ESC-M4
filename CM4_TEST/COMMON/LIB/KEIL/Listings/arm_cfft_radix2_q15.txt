; generated by Component: ARM Compiler 5.06 update 4 (build 422) Tool: ArmCC [4d3604]
; commandline ArmCC [--c99 --list --split_sections --debug -c --asm --interleave -o.\objects\arm_cfft_radix2_q15.o --asm_dir=.\Listings\ --list_dir=.\Listings\ --depend=.\objects\arm_cfft_radix2_q15.d --cpu=Cortex-M4.fp --apcs=interwork -O3 --diag_suppress=9931 -I..\..\SRC\CMSIS_DSP_4_5\inc -IC:\Users\emh203\Documents\GitHub\ESC-M4\CM4_TEST\COMMON\LIB\KEIL\RTE\_CMSIS_DSP_4_5_O3 -IC:\Keil_v5\ARM\PACK\ARM\CMSIS\5.0.0\Device\ARM\ARMCM4\Include -IC:\Keil_v5\ARM\CMSIS\Include -D__UVISION_VERSION=522 -DARMCM4_FP -D__FPU_PRESENT=1 -DARM_MATH_CM4 -D__CC_ARM --omf_browse=.\objects\arm_cfft_radix2_q15.crf ..\..\SRC\CMSIS_DSP_4_5\src\TransformFunctions\arm_cfft_radix2_q15.c]
                          THUMB

                          AREA ||i.arm_cfft_radix2_q15||, CODE, READONLY, ALIGN=1

                  arm_cfft_radix2_q15 PROC
;;;79     
;;;80     void arm_cfft_radix2_q15(
000000  b570              PUSH     {r4-r6,lr}
;;;81       const arm_cfft_radix2_instance_q15 * S,
;;;82       q15_t * pSrc)
;;;83     {
000002  4604              MOV      r4,r0
;;;84     
;;;85       if(S->ifftFlag == 1u)
000004  7880              LDRB     r0,[r0,#2]
000006  460d              MOV      r5,r1                 ;83
;;;86       {
;;;87         arm_radix2_butterfly_inverse_q15(pSrc, S->fftLen,
000008  8821              LDRH     r1,[r4,#0]
00000a  89a3              LDRH     r3,[r4,#0xc]
00000c  6862              LDR      r2,[r4,#4]            ;85
00000e  2801              CMP      r0,#1                 ;85
;;;88                                          S->pTwiddle, S->twidCoefModifier);
;;;89       }
;;;90       else
;;;91       {
;;;92         arm_radix2_butterfly_q15(pSrc, S->fftLen,
000010  4628              MOV      r0,r5
000012  d009              BEQ      |L1.40|
000014  f7fffffe          BL       arm_radix2_butterfly_q15
                  |L1.24|
;;;93                                  S->pTwiddle, S->twidCoefModifier);
;;;94       }
;;;95     
;;;96       arm_bitreversal_q15(pSrc, S->fftLen, S->bitRevFactor, S->pBitRevTable);
000018  89e2              LDRH     r2,[r4,#0xe]
00001a  8821              LDRH     r1,[r4,#0]
00001c  4628              MOV      r0,r5
00001e  68a3              LDR      r3,[r4,#8]
000020  e8bd4070          POP      {r4-r6,lr}
000024  f7ffbffe          B.W      arm_bitreversal_q15
                  |L1.40|
000028  f7fffffe          BL       arm_radix2_butterfly_inverse_q15
00002c  e7f4              B        |L1.24|
;;;97     }
;;;98     
                          ENDP


                          AREA ||i.arm_radix2_butterfly_inverse_q15||, CODE, READONLY, ALIGN=2

                  arm_radix2_butterfly_inverse_q15 PROC
;;;431    
;;;432    void arm_radix2_butterfly_inverse_q15(
000000  e92d4fff          PUSH     {r0-r11,lr}
;;;433      q15_t * pSrc,
;;;434      uint32_t fftLen,
;;;435      q15_t * pCoef,
;;;436      uint16_t twidCoefModifier)
;;;437    {
;;;438    #ifndef ARM_MATH_CM0_FAMILY
;;;439    
;;;440      unsigned i, j, k, l;
;;;441      unsigned n1, n2, ia;
;;;442      q15_t in;
;;;443      q31_t T, S, R;
;;;444      q31_t coeff, out1, out2;
;;;445    
;;;446      //N = fftLen; 
;;;447      n2 = fftLen;
;;;448    
;;;449      n1 = n2;
;;;450      n2 = n2 >> 1;
000004  084a              LSRS     r2,r1,#1
;;;451      ia = 0;
000006  2500              MOVS     r5,#0
;;;452    
;;;453      // loop for groups 
;;;454      for (i = 0; i < n2; i++)
000008  462c              MOV      r4,r5
00000a  e053              B        |L2.180|
                  |L2.12|
;;;455      {
;;;456        coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
00000c  9e02              LDR      r6,[sp,#8]
;;;457    
;;;458        ia = ia + twidCoefModifier;
;;;459    
;;;460        l = i + n2;
;;;461    
;;;462        T = _SIMD32_OFFSET(pSrc + (2 * i));
00000e  eb000884          ADD      r8,r0,r4,LSL #2
000012  eb060685          ADD      r6,r6,r5,LSL #2       ;456
000016  eb050a03          ADD      r10,r5,r3             ;458
00001a  f8d85000          LDR      r5,[r8,#0]
00001e  f8d69000          LDR      r9,[r6,#0]            ;456
000022  18a7              ADDS     r7,r4,r2              ;460
;;;463        in = ((int16_t) (T & 0xFFFF)) >> 1;
000024  f345064e          SBFX     r6,r5,#1,#15
;;;464        T = ((T >> 1) & 0xFFFF0000) | (in & 0xFFFF);
000028  106d              ASRS     r5,r5,#1
00002a  eac60505          PKHBT    r5,r6,r5
;;;465    
;;;466        S = _SIMD32_OFFSET(pSrc + (2 * l));
00002e  eb000b87          ADD      r11,r0,r7,LSL #2
000032  f8db6000          LDR      r6,[r11,#0]
;;;467        in = ((int16_t) (S & 0xFFFF)) >> 1;
000036  f3460c4e          SBFX     r12,r6,#1,#15
;;;468        S = ((S >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00003a  1076              ASRS     r6,r6,#1
00003c  eacc0606          PKHBT    r6,r12,r6
;;;469    
;;;470        R = __QSUB16(T, S);
000040  fad5fc16          QSUB16   r12,r5,r6
;;;471    
;;;472        _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
000044  fa95f526          SHADD16  r5,r5,r6
000048  f8c85000          STR      r5,[r8,#0]
;;;473    
;;;474    #ifndef ARM_MATH_BIG_ENDIAN
;;;475    
;;;476        out1 = __SMUSD(coeff, R) >> 16;
00004c  fb49f50c          SMUSD    r5,r9,r12
000050  0c2d              LSRS     r5,r5,#16
;;;477        out2 = __SMUADX(coeff, R);
000052  fb29f61c          SMUADX   r6,r9,r12
;;;478    #else
;;;479    
;;;480        out1 = __SMUADX(R, coeff) >> 16u;
;;;481        out2 = __SMUSD(__QSUB(0, coeff), R);
;;;482    
;;;483    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;484    
;;;485        _SIMD32_OFFSET(pSrc + (2u * l)) =
000056  eac50506          PKHBT    r5,r5,r6
00005a  f8cb5000          STR      r5,[r11,#0]
;;;486          (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;487    
;;;488        coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
00005e  9e02              LDR      r6,[sp,#8]
;;;489    
;;;490        ia = ia + twidCoefModifier;
000060  1c64              ADDS     r4,r4,#1
000062  eb06058a          ADD      r5,r6,r10,LSL #2      ;488
;;;491    
;;;492        // loop for butterfly 
;;;493        i++;
;;;494        l++;
;;;495    
;;;496        T = _SIMD32_OFFSET(pSrc + (2 * i));
000066  eb000884          ADD      r8,r0,r4,LSL #2
00006a  f8d59000          LDR      r9,[r5,#0]            ;488
00006e  f8d86000          LDR      r6,[r8,#0]
000072  eb0a0503          ADD      r5,r10,r3             ;490
;;;497        in = ((int16_t) (T & 0xFFFF)) >> 1;
000076  f3460c4e          SBFX     r12,r6,#1,#15
;;;498        T = ((T >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00007a  1076              ASRS     r6,r6,#1
00007c  eacc0606          PKHBT    r6,r12,r6
000080  1c7f              ADDS     r7,r7,#1
;;;499    
;;;500        S = _SIMD32_OFFSET(pSrc + (2 * l));
000082  eb000a87          ADD      r10,r0,r7,LSL #2
000086  f8da7000          LDR      r7,[r10,#0]
;;;501        in = ((int16_t) (S & 0xFFFF)) >> 1;
00008a  f3470c4e          SBFX     r12,r7,#1,#15
;;;502        S = ((S >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00008e  107f              ASRS     r7,r7,#1
000090  eacc0707          PKHBT    r7,r12,r7
;;;503    
;;;504        R = __QSUB16(T, S);
000094  fad6fc17          QSUB16   r12,r6,r7
;;;505    
;;;506        _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
000098  fa96f627          SHADD16  r6,r6,r7
00009c  f8c86000          STR      r6,[r8,#0]
;;;507    
;;;508    #ifndef ARM_MATH_BIG_ENDIAN
;;;509    
;;;510        out1 = __SMUSD(coeff, R) >> 16;
0000a0  fb49f60c          SMUSD    r6,r9,r12
0000a4  0c37              LSRS     r7,r6,#16
;;;511        out2 = __SMUADX(coeff, R);
0000a6  fb29f61c          SMUADX   r6,r9,r12
;;;512    #else
;;;513    
;;;514        out1 = __SMUADX(R, coeff) >> 16u;
;;;515        out2 = __SMUSD(__QSUB(0, coeff), R);
;;;516    
;;;517    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;518    
;;;519        _SIMD32_OFFSET(pSrc + (2u * l)) =
0000aa  eac70606          PKHBT    r6,r7,r6
0000ae  f8ca6000          STR      r6,[r10,#0]
0000b2  1c64              ADDS     r4,r4,#1
                  |L2.180|
0000b4  4294              CMP      r4,r2                 ;454
0000b6  d3a9              BCC      |L2.12|
;;;520          (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;521    
;;;522      }                             // groups loop end 
;;;523    
;;;524      twidCoefModifier = twidCoefModifier << 1u;
0000b8  f64f74ff          MOV      r4,#0xffff
0000bc  ea040343          AND      r3,r4,r3,LSL #1
;;;525    
;;;526      // loop for stage 
;;;527      for (k = fftLen / 2; k > 2; k = k >> 1)
0000c0  4692              MOV      r10,r2
0000c2  9303              STR      r3,[sp,#0xc]
0000c4  e04f              B        |L2.358|
;;;528      {
;;;529        n1 = n2;
;;;530        n2 = n2 >> 1;
0000c6  bf00              NOP      
                  |L2.200|
;;;531        ia = 0;
0000c8  2600              MOVS     r6,#0
0000ca  ea4f0259          LSR      r2,r9,#1              ;530
;;;532    
;;;533        // loop for groups 
;;;534        for (j = 0; j < n2; j++)
0000ce  4634              MOV      r4,r6
0000d0  e03f              B        |L2.338|
                  |L2.210|
;;;535        {
;;;536          coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
0000d2  9b02              LDR      r3,[sp,#8]
0000d4  eb030386          ADD      r3,r3,r6,LSL #2
0000d8  681d              LDR      r5,[r3,#0]
;;;537    
;;;538          ia = ia + twidCoefModifier;
0000da  9b03              LDR      r3,[sp,#0xc]
0000dc  441e              ADD      r6,r6,r3
;;;539    
;;;540          // loop for butterfly 
;;;541          for (i = j; i < fftLen; i += n1)
0000de  4623              MOV      r3,r4
0000e0  e034              B        |L2.332|
;;;542          {
;;;543            l = i + n2;
0000e2  bf00              NOP      
                  |L2.228|
0000e4  eb030c02          ADD      r12,r3,r2
;;;544    
;;;545            T = _SIMD32_OFFSET(pSrc + (2 * i));
0000e8  eb000b83          ADD      r11,r0,r3,LSL #2
;;;546    
;;;547            S = _SIMD32_OFFSET(pSrc + (2 * l));
0000ec  eb000e8c          ADD      lr,r0,r12,LSL #2
0000f0  f8db7000          LDR      r7,[r11,#0]           ;545
0000f4  f8dec000          LDR      r12,[lr,#0]
;;;548    
;;;549            R = __QSUB16(T, S);
0000f8  fad7f81c          QSUB16   r8,r7,r12
;;;550    
;;;551            _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
0000fc  fa97fc2c          SHADD16  r12,r7,r12
000100  f8cbc000          STR      r12,[r11,#0]
;;;552    
;;;553    #ifndef ARM_MATH_BIG_ENDIAN
;;;554    
;;;555            out1 = __SMUSD(coeff, R) >> 16;
000104  fb45f708          SMUSD    r7,r5,r8
000108  0c3f              LSRS     r7,r7,#16
;;;556            out2 = __SMUADX(coeff, R);
00010a  fb25fc18          SMUADX   r12,r5,r8
;;;557    
;;;558    #else
;;;559    
;;;560            out1 = __SMUADX(R, coeff) >> 16u;
;;;561            out2 = __SMUSD(__QSUB(0, coeff), R);
;;;562    
;;;563    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;564    
;;;565            _SIMD32_OFFSET(pSrc + (2u * l)) =
00010e  eac7070c          PKHBT    r7,r7,r12
;;;566              (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;567    
;;;568            i += n1;
000112  444b              ADD      r3,r3,r9
000114  f8ce7000          STR      r7,[lr,#0]            ;565
;;;569    
;;;570            l = i + n2;
000118  eb030c02          ADD      r12,r3,r2
;;;571    
;;;572            T = _SIMD32_OFFSET(pSrc + (2 * i));
00011c  eb000b83          ADD      r11,r0,r3,LSL #2
;;;573    
;;;574            S = _SIMD32_OFFSET(pSrc + (2 * l));
000120  eb000e8c          ADD      lr,r0,r12,LSL #2
000124  f8db7000          LDR      r7,[r11,#0]           ;572
000128  f8dec000          LDR      r12,[lr,#0]
;;;575    
;;;576            R = __QSUB16(T, S);
00012c  fad7f81c          QSUB16   r8,r7,r12
;;;577    
;;;578            _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
000130  fa97fc2c          SHADD16  r12,r7,r12
000134  f8cbc000          STR      r12,[r11,#0]
;;;579    
;;;580    #ifndef ARM_MATH_BIG_ENDIAN
;;;581    
;;;582            out1 = __SMUSD(coeff, R) >> 16;
000138  fb45f708          SMUSD    r7,r5,r8
00013c  0c3f              LSRS     r7,r7,#16
;;;583            out2 = __SMUADX(coeff, R);
00013e  fb25fc18          SMUADX   r12,r5,r8
;;;584    #else
;;;585    
;;;586            out1 = __SMUADX(R, coeff) >> 16u;
;;;587            out2 = __SMUSD(__QSUB(0, coeff), R);
;;;588    
;;;589    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;590    
;;;591            _SIMD32_OFFSET(pSrc + (2u * l)) =
000142  eac7070c          PKHBT    r7,r7,r12
000146  f8ce7000          STR      r7,[lr,#0]
00014a  444b              ADD      r3,r3,r9              ;541
                  |L2.332|
00014c  428b              CMP      r3,r1                 ;541
00014e  d3c9              BCC      |L2.228|
000150  1c64              ADDS     r4,r4,#1              ;541
                  |L2.338|
000152  4294              CMP      r4,r2                 ;534
000154  d3bd              BCC      |L2.210|
;;;592              (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;593    
;;;594          }                         // butterfly loop end 
;;;595    
;;;596        }                           // groups loop end 
;;;597    
;;;598        twidCoefModifier = twidCoefModifier << 1u;
000156  9b03              LDR      r3,[sp,#0xc]
000158  f64f74ff          MOV      r4,#0xffff
00015c  ea040343          AND      r3,r4,r3,LSL #1
000160  ea4f0a5a          LSR      r10,r10,#1            ;527
000164  9303              STR      r3,[sp,#0xc]          ;527
                  |L2.358|
000166  f1ba0f02          CMP      r10,#2                ;527
;;;599      }                             // stages loop end 
;;;600    
;;;601      n1 = n2;
00016a  4691              MOV      r9,r2
00016c  d8ac              BHI      |L2.200|
;;;602      n2 = n2 >> 1;
00016e  ea4f0459          LSR      r4,r9,#1
;;;603      ia = 0;
;;;604    
;;;605      // loop for groups 
;;;606      for (j = 0; j < n2; j++)
000172  2300              MOVS     r3,#0
000174  e015              B        |L2.418|
                  |L2.374|
;;;607      {
;;;608        coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
;;;609    
;;;610        ia = ia + twidCoefModifier;
;;;611    
;;;612        // loop for butterfly 
;;;613        for (i = j; i < fftLen; i += n1)
000176  461a              MOV      r2,r3
000178  e010              B        |L2.412|
                  |L2.378|
;;;614        {
;;;615          l = i + n2;
00017a  1916              ADDS     r6,r2,r4
;;;616    
;;;617          T = _SIMD32_OFFSET(pSrc + (2 * i));
00017c  eb000c82          ADD      r12,r0,r2,LSL #2
;;;618    
;;;619          S = _SIMD32_OFFSET(pSrc + (2 * l));
000180  eb000786          ADD      r7,r0,r6,LSL #2
000184  f8dc5000          LDR      r5,[r12,#0]           ;617
000188  683e              LDR      r6,[r7,#0]
;;;620    
;;;621          R = __QSUB16(T, S);
00018a  fad5f816          QSUB16   r8,r5,r6
;;;622    
;;;623          _SIMD32_OFFSET(pSrc + (2 * i)) = __QADD16(T, S);
00018e  fa95f516          QADD16   r5,r5,r6
000192  f8cc5000          STR      r5,[r12,#0]
;;;624    
;;;625          _SIMD32_OFFSET(pSrc + (2u * l)) = R;
000196  f8c78000          STR      r8,[r7,#0]
00019a  444a              ADD      r2,r2,r9              ;613
                  |L2.412|
00019c  428a              CMP      r2,r1                 ;613
00019e  d3ec              BCC      |L2.378|
0001a0  1c5b              ADDS     r3,r3,#1              ;613
                  |L2.418|
0001a2  42a3              CMP      r3,r4                 ;606
0001a4  d3e7              BCC      |L2.374|
;;;626    
;;;627        }                           // butterfly loop end 
;;;628    
;;;629      }                             // groups loop end 
;;;630    
;;;631      twidCoefModifier = twidCoefModifier << 1u;
;;;632    
;;;633    #else
;;;634    
;;;635    
;;;636      unsigned i, j, k, l;
;;;637      unsigned n1, n2, ia;
;;;638      q15_t xt, yt, cosVal, sinVal;
;;;639    
;;;640      //N = fftLen; 
;;;641      n2 = fftLen;
;;;642    
;;;643      n1 = n2;
;;;644      n2 = n2 >> 1;
;;;645      ia = 0;
;;;646    
;;;647      // loop for groups 
;;;648      for (j = 0; j < n2; j++)
;;;649      {
;;;650        cosVal = pCoef[ia * 2];
;;;651        sinVal = pCoef[(ia * 2) + 1];
;;;652        ia = ia + twidCoefModifier;
;;;653    
;;;654        // loop for butterfly 
;;;655        for (i = j; i < fftLen; i += n1)
;;;656        {
;;;657          l = i + n2;
;;;658          xt = (pSrc[2 * i] >> 1u) - (pSrc[2 * l] >> 1u);
;;;659          pSrc[2 * i] = ((pSrc[2 * i] >> 1u) + (pSrc[2 * l] >> 1u)) >> 1u;
;;;660    
;;;661          yt = (pSrc[2 * i + 1] >> 1u) - (pSrc[2 * l + 1] >> 1u);
;;;662          pSrc[2 * i + 1] =
;;;663            ((pSrc[2 * l + 1] >> 1u) + (pSrc[2 * i + 1] >> 1u)) >> 1u;
;;;664    
;;;665          pSrc[2u * l] = (((int16_t) (((q31_t) xt * cosVal) >> 16)) -
;;;666                          ((int16_t) (((q31_t) yt * sinVal) >> 16)));
;;;667    
;;;668          pSrc[2u * l + 1u] = (((int16_t) (((q31_t) yt * cosVal) >> 16)) +
;;;669                               ((int16_t) (((q31_t) xt * sinVal) >> 16)));
;;;670    
;;;671        }                           // butterfly loop end 
;;;672    
;;;673      }                             // groups loop end 
;;;674    
;;;675      twidCoefModifier = twidCoefModifier << 1u;
;;;676    
;;;677      // loop for stage 
;;;678      for (k = fftLen / 2; k > 2; k = k >> 1)
;;;679      {
;;;680        n1 = n2;
;;;681        n2 = n2 >> 1;
;;;682        ia = 0;
;;;683    
;;;684        // loop for groups 
;;;685        for (j = 0; j < n2; j++)
;;;686        {
;;;687          cosVal = pCoef[ia * 2];
;;;688          sinVal = pCoef[(ia * 2) + 1];
;;;689          ia = ia + twidCoefModifier;
;;;690    
;;;691          // loop for butterfly 
;;;692          for (i = j; i < fftLen; i += n1)
;;;693          {
;;;694            l = i + n2;
;;;695            xt = pSrc[2 * i] - pSrc[2 * l];
;;;696            pSrc[2 * i] = (pSrc[2 * i] + pSrc[2 * l]) >> 1u;
;;;697    
;;;698            yt = pSrc[2 * i + 1] - pSrc[2 * l + 1];
;;;699            pSrc[2 * i + 1] = (pSrc[2 * l + 1] + pSrc[2 * i + 1]) >> 1u;
;;;700    
;;;701            pSrc[2u * l] = (((int16_t) (((q31_t) xt * cosVal) >> 16)) -
;;;702                            ((int16_t) (((q31_t) yt * sinVal) >> 16)));
;;;703    
;;;704            pSrc[2u * l + 1u] = (((int16_t) (((q31_t) yt * cosVal) >> 16)) +
;;;705                                 ((int16_t) (((q31_t) xt * sinVal) >> 16)));
;;;706    
;;;707          }                         // butterfly loop end 
;;;708    
;;;709        }                           // groups loop end 
;;;710    
;;;711        twidCoefModifier = twidCoefModifier << 1u;
;;;712      }                             // stages loop end 
;;;713    
;;;714      n1 = n2;
;;;715      n2 = n2 >> 1;
;;;716      ia = 0;
;;;717    
;;;718      cosVal = pCoef[ia * 2];
;;;719      sinVal = pCoef[(ia * 2) + 1];
;;;720    
;;;721      ia = ia + twidCoefModifier;
;;;722    
;;;723      // loop for butterfly 
;;;724      for (i = 0; i < fftLen; i += n1)
;;;725      {
;;;726        l = i + n2;
;;;727        xt = pSrc[2 * i] - pSrc[2 * l];
;;;728        pSrc[2 * i] = (pSrc[2 * i] + pSrc[2 * l]);
;;;729    
;;;730        yt = pSrc[2 * i + 1] - pSrc[2 * l + 1];
;;;731        pSrc[2 * i + 1] = (pSrc[2 * l + 1] + pSrc[2 * i + 1]);
;;;732    
;;;733        pSrc[2u * l] = xt;
;;;734    
;;;735        pSrc[2u * l + 1u] = yt;
;;;736    
;;;737      }                             // groups loop end 
;;;738    
;;;739    
;;;740    #endif //             #ifndef ARM_MATH_CM0_FAMILY
;;;741    
;;;742    }
0001a6  e8bd8fff          POP      {r0-r11,pc}
                          ENDP


                          AREA ||i.arm_radix2_butterfly_q15||, CODE, READONLY, ALIGN=1

                  arm_radix2_butterfly_q15 PROC
;;;102    
;;;103    void arm_radix2_butterfly_q15(
000000  e92d4fff          PUSH     {r0-r11,lr}
;;;104      q15_t * pSrc,
;;;105      uint32_t fftLen,
;;;106      q15_t * pCoef,
;;;107      uint16_t twidCoefModifier)
;;;108    {
;;;109    #ifndef ARM_MATH_CM0_FAMILY
;;;110    
;;;111      unsigned i, j, k, l;
;;;112      unsigned n1, n2, ia;
;;;113      q15_t in;
;;;114      q31_t T, S, R;
;;;115      q31_t coeff, out1, out2;
;;;116    
;;;117      //N = fftLen; 
;;;118      n2 = fftLen;
;;;119    
;;;120      n1 = n2;
;;;121      n2 = n2 >> 1;
000004  084a              LSRS     r2,r1,#1
;;;122      ia = 0;
000006  2500              MOVS     r5,#0
;;;123    
;;;124      // loop for groups 
;;;125      for (i = 0; i < n2; i++)
000008  462c              MOV      r4,r5
00000a  e053              B        |L3.180|
                  |L3.12|
;;;126      {
;;;127        coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
00000c  9e02              LDR      r6,[sp,#8]
;;;128    
;;;129        ia = ia + twidCoefModifier;
;;;130    
;;;131        l = i + n2;
;;;132    
;;;133        T = _SIMD32_OFFSET(pSrc + (2 * i));
00000e  eb000884          ADD      r8,r0,r4,LSL #2
000012  eb060685          ADD      r6,r6,r5,LSL #2       ;127
000016  eb050a03          ADD      r10,r5,r3             ;129
00001a  f8d85000          LDR      r5,[r8,#0]
00001e  f8d69000          LDR      r9,[r6,#0]            ;127
000022  18a7              ADDS     r7,r4,r2              ;131
;;;134        in = ((int16_t) (T & 0xFFFF)) >> 1;
000024  f345064e          SBFX     r6,r5,#1,#15
;;;135        T = ((T >> 1) & 0xFFFF0000) | (in & 0xFFFF);
000028  106d              ASRS     r5,r5,#1
00002a  eac60505          PKHBT    r5,r6,r5
;;;136    
;;;137        S = _SIMD32_OFFSET(pSrc + (2 * l));
00002e  eb000b87          ADD      r11,r0,r7,LSL #2
000032  f8db6000          LDR      r6,[r11,#0]
;;;138        in = ((int16_t) (S & 0xFFFF)) >> 1;
000036  f3460c4e          SBFX     r12,r6,#1,#15
;;;139        S = ((S >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00003a  1076              ASRS     r6,r6,#1
00003c  eacc0606          PKHBT    r6,r12,r6
;;;140    
;;;141        R = __QSUB16(T, S);
000040  fad5fc16          QSUB16   r12,r5,r6
;;;142    
;;;143        _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
000044  fa95f526          SHADD16  r5,r5,r6
000048  f8c85000          STR      r5,[r8,#0]
;;;144    
;;;145    #ifndef ARM_MATH_BIG_ENDIAN
;;;146    
;;;147        out1 = __SMUAD(coeff, R) >> 16;
00004c  fb29f50c          SMUAD    r5,r9,r12
000050  0c2d              LSRS     r5,r5,#16
;;;148        out2 = __SMUSDX(coeff, R);
000052  fb49f61c          SMUSDX   r6,r9,r12
;;;149    
;;;150    #else
;;;151    
;;;152        out1 = __SMUSDX(R, coeff) >> 16u;
;;;153        out2 = __SMUAD(coeff, R);
;;;154    
;;;155    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;156    
;;;157        _SIMD32_OFFSET(pSrc + (2u * l)) =
000056  eac50506          PKHBT    r5,r5,r6
00005a  f8cb5000          STR      r5,[r11,#0]
;;;158          (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;159    
;;;160        coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
00005e  9e02              LDR      r6,[sp,#8]
;;;161    
;;;162        ia = ia + twidCoefModifier;
000060  1c64              ADDS     r4,r4,#1
000062  eb06058a          ADD      r5,r6,r10,LSL #2      ;160
;;;163    
;;;164        // loop for butterfly 
;;;165        i++;
;;;166        l++;
;;;167    
;;;168        T = _SIMD32_OFFSET(pSrc + (2 * i));
000066  eb000884          ADD      r8,r0,r4,LSL #2
00006a  f8d59000          LDR      r9,[r5,#0]            ;160
00006e  f8d86000          LDR      r6,[r8,#0]
000072  eb0a0503          ADD      r5,r10,r3             ;162
;;;169        in = ((int16_t) (T & 0xFFFF)) >> 1;
000076  f3460c4e          SBFX     r12,r6,#1,#15
;;;170        T = ((T >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00007a  1076              ASRS     r6,r6,#1
00007c  eacc0606          PKHBT    r6,r12,r6
000080  1c7f              ADDS     r7,r7,#1
;;;171    
;;;172        S = _SIMD32_OFFSET(pSrc + (2 * l));
000082  eb000a87          ADD      r10,r0,r7,LSL #2
000086  f8da7000          LDR      r7,[r10,#0]
;;;173        in = ((int16_t) (S & 0xFFFF)) >> 1;
00008a  f3470c4e          SBFX     r12,r7,#1,#15
;;;174        S = ((S >> 1) & 0xFFFF0000) | (in & 0xFFFF);
00008e  107f              ASRS     r7,r7,#1
000090  eacc0707          PKHBT    r7,r12,r7
;;;175    
;;;176        R = __QSUB16(T, S);
000094  fad6fc17          QSUB16   r12,r6,r7
;;;177    
;;;178        _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
000098  fa96f627          SHADD16  r6,r6,r7
00009c  f8c86000          STR      r6,[r8,#0]
;;;179    
;;;180    #ifndef ARM_MATH_BIG_ENDIAN
;;;181    
;;;182        out1 = __SMUAD(coeff, R) >> 16;
0000a0  fb29f60c          SMUAD    r6,r9,r12
0000a4  0c37              LSRS     r7,r6,#16
;;;183        out2 = __SMUSDX(coeff, R);
0000a6  fb49f61c          SMUSDX   r6,r9,r12
;;;184    
;;;185    #else
;;;186    
;;;187        out1 = __SMUSDX(R, coeff) >> 16u;
;;;188        out2 = __SMUAD(coeff, R);
;;;189    
;;;190    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;191    
;;;192        _SIMD32_OFFSET(pSrc + (2u * l)) =
0000aa  eac70606          PKHBT    r6,r7,r6
0000ae  f8ca6000          STR      r6,[r10,#0]
0000b2  1c64              ADDS     r4,r4,#1
                  |L3.180|
0000b4  4294              CMP      r4,r2                 ;125
0000b6  d3a9              BCC      |L3.12|
;;;193          (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;194    
;;;195      }                             // groups loop end 
;;;196    
;;;197      twidCoefModifier = twidCoefModifier << 1u;
0000b8  f64f74ff          MOV      r4,#0xffff
0000bc  ea040343          AND      r3,r4,r3,LSL #1
;;;198    
;;;199      // loop for stage 
;;;200      for (k = fftLen / 2; k > 2; k = k >> 1)
0000c0  4692              MOV      r10,r2
0000c2  9303              STR      r3,[sp,#0xc]
0000c4  e04d              B        |L3.354|
                  |L3.198|
;;;201      {
;;;202        n1 = n2;
0000c6  4691              MOV      r9,r2
;;;203        n2 = n2 >> 1;
0000c8  0852              LSRS     r2,r2,#1
;;;204        ia = 0;
0000ca  2600              MOVS     r6,#0
;;;205    
;;;206        // loop for groups 
;;;207        for (j = 0; j < n2; j++)
0000cc  4633              MOV      r3,r6
0000ce  e03e              B        |L3.334|
                  |L3.208|
;;;208        {
;;;209          coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
0000d0  9c02              LDR      r4,[sp,#8]
;;;210    
;;;211          ia = ia + twidCoefModifier;
0000d2  9d03              LDR      r5,[sp,#0xc]
0000d4  eb040486          ADD      r4,r4,r6,LSL #2       ;209
0000d8  442e              ADD      r6,r6,r5
0000da  6824              LDR      r4,[r4,#0]            ;209
;;;212    
;;;213          // loop for butterfly 
;;;214          for (i = j; i < fftLen; i += n1)
0000dc  461d              MOV      r5,r3
0000de  e033              B        |L3.328|
                  |L3.224|
;;;215          {
;;;216            l = i + n2;
0000e0  eb050c02          ADD      r12,r5,r2
;;;217    
;;;218            T = _SIMD32_OFFSET(pSrc + (2 * i));
0000e4  eb000b85          ADD      r11,r0,r5,LSL #2
;;;219    
;;;220            S = _SIMD32_OFFSET(pSrc + (2 * l));
0000e8  eb000e8c          ADD      lr,r0,r12,LSL #2
0000ec  f8db7000          LDR      r7,[r11,#0]           ;218
0000f0  f8dec000          LDR      r12,[lr,#0]
;;;221    
;;;222            R = __QSUB16(T, S);
0000f4  fad7f81c          QSUB16   r8,r7,r12
;;;223    
;;;224            _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
0000f8  fa97fc2c          SHADD16  r12,r7,r12
0000fc  f8cbc000          STR      r12,[r11,#0]
;;;225    
;;;226    #ifndef ARM_MATH_BIG_ENDIAN
;;;227    
;;;228            out1 = __SMUAD(coeff, R) >> 16;
000100  fb24f708          SMUAD    r7,r4,r8
000104  0c3f              LSRS     r7,r7,#16
;;;229            out2 = __SMUSDX(coeff, R);
000106  fb44fc18          SMUSDX   r12,r4,r8
;;;230    
;;;231    #else
;;;232    
;;;233            out1 = __SMUSDX(R, coeff) >> 16u;
;;;234            out2 = __SMUAD(coeff, R);
;;;235    
;;;236    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;237    
;;;238            _SIMD32_OFFSET(pSrc + (2u * l)) =
00010a  eac7070c          PKHBT    r7,r7,r12
;;;239              (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;240    
;;;241            i += n1;
00010e  444d              ADD      r5,r5,r9
000110  f8ce7000          STR      r7,[lr,#0]            ;238
;;;242    
;;;243            l = i + n2;
000114  eb050c02          ADD      r12,r5,r2
;;;244    
;;;245            T = _SIMD32_OFFSET(pSrc + (2 * i));
000118  eb000b85          ADD      r11,r0,r5,LSL #2
;;;246    
;;;247            S = _SIMD32_OFFSET(pSrc + (2 * l));
00011c  eb000e8c          ADD      lr,r0,r12,LSL #2
000120  f8db7000          LDR      r7,[r11,#0]           ;245
000124  f8dec000          LDR      r12,[lr,#0]
;;;248    
;;;249            R = __QSUB16(T, S);
000128  fad7f81c          QSUB16   r8,r7,r12
;;;250    
;;;251            _SIMD32_OFFSET(pSrc + (2 * i)) = __SHADD16(T, S);
00012c  fa97fc2c          SHADD16  r12,r7,r12
000130  f8cbc000          STR      r12,[r11,#0]
;;;252    
;;;253    #ifndef ARM_MATH_BIG_ENDIAN
;;;254    
;;;255            out1 = __SMUAD(coeff, R) >> 16;
000134  fb24f708          SMUAD    r7,r4,r8
000138  0c3f              LSRS     r7,r7,#16
;;;256            out2 = __SMUSDX(coeff, R);
00013a  fb44fc18          SMUSDX   r12,r4,r8
;;;257    
;;;258    #else
;;;259    
;;;260            out1 = __SMUSDX(R, coeff) >> 16u;
;;;261            out2 = __SMUAD(coeff, R);
;;;262    
;;;263    #endif //     #ifndef ARM_MATH_BIG_ENDIAN
;;;264    
;;;265            _SIMD32_OFFSET(pSrc + (2u * l)) =
00013e  eac7070c          PKHBT    r7,r7,r12
000142  f8ce7000          STR      r7,[lr,#0]
000146  444d              ADD      r5,r5,r9              ;214
                  |L3.328|
000148  428d              CMP      r5,r1                 ;214
00014a  d3c9              BCC      |L3.224|
00014c  1c5b              ADDS     r3,r3,#1              ;214
                  |L3.334|
00014e  4293              CMP      r3,r2                 ;207
000150  d3be              BCC      |L3.208|
;;;266              (q31_t) ((out2) & 0xFFFF0000) | (out1 & 0x0000FFFF);
;;;267    
;;;268          }                         // butterfly loop end 
;;;269    
;;;270        }                           // groups loop end 
;;;271    
;;;272        twidCoefModifier = twidCoefModifier << 1u;
000152  9c03              LDR      r4,[sp,#0xc]
000154  f64f73ff          MOV      r3,#0xffff
000158  ea030344          AND      r3,r3,r4,LSL #1
00015c  ea4f0a5a          LSR      r10,r10,#1            ;200
000160  9303              STR      r3,[sp,#0xc]          ;200
                  |L3.354|
000162  f1ba0f02          CMP      r10,#2                ;200
000166  d8ae              BHI      |L3.198|
;;;273      }                             // stages loop end 
;;;274    
;;;275      n1 = n2;
;;;276      n2 = n2 >> 1;
000168  0854              LSRS     r4,r2,#1
;;;277      ia = 0;
;;;278    
;;;279      coeff = _SIMD32_OFFSET(pCoef + (ia * 2u));
;;;280    
;;;281      ia = ia + twidCoefModifier;
;;;282    
;;;283      // loop for butterfly 
;;;284      for (i = 0; i < fftLen; i += n1)
00016a  2300              MOVS     r3,#0
00016c  e021              B        |L3.434|
                  |L3.366|
;;;285      {
;;;286        l = i + n2;
00016e  191e              ADDS     r6,r3,r4
;;;287    
;;;288        T = _SIMD32_OFFSET(pSrc + (2 * i));
000170  eb000c83          ADD      r12,r0,r3,LSL #2
;;;289    
;;;290        S = _SIMD32_OFFSET(pSrc + (2 * l));
000174  eb000786          ADD      r7,r0,r6,LSL #2
000178  f8dc5000          LDR      r5,[r12,#0]           ;288
00017c  683e              LDR      r6,[r7,#0]
;;;291    
;;;292        R = __QSUB16(T, S);
00017e  fad5f816          QSUB16   r8,r5,r6
;;;293    
;;;294        _SIMD32_OFFSET(pSrc + (2 * i)) = __QADD16(T, S);
000182  fa95f516          QADD16   r5,r5,r6
000186  f8cc5000          STR      r5,[r12,#0]
;;;295    
;;;296        _SIMD32_OFFSET(pSrc + (2u * l)) = R;
;;;297    
;;;298        i += n1;
00018a  4413              ADD      r3,r3,r2
00018c  f8c78000          STR      r8,[r7,#0]            ;296
;;;299        l = i + n2;
000190  191e              ADDS     r6,r3,r4
;;;300    
;;;301        T = _SIMD32_OFFSET(pSrc + (2 * i));
000192  eb000c83          ADD      r12,r0,r3,LSL #2
;;;302    
;;;303        S = _SIMD32_OFFSET(pSrc + (2 * l));
000196  eb000786          ADD      r7,r0,r6,LSL #2
00019a  f8dc5000          LDR      r5,[r12,#0]           ;301
00019e  683e              LDR      r6,[r7,#0]
;;;304    
;;;305        R = __QSUB16(T, S);
0001a0  fad5f816          QSUB16   r8,r5,r6
;;;306    
;;;307        _SIMD32_OFFSET(pSrc + (2 * i)) = __QADD16(T, S);
0001a4  fa95f516          QADD16   r5,r5,r6
0001a8  f8cc5000          STR      r5,[r12,#0]
;;;308    
;;;309        _SIMD32_OFFSET(pSrc + (2u * l)) = R;
0001ac  f8c78000          STR      r8,[r7,#0]
0001b0  4413              ADD      r3,r3,r2              ;284
                  |L3.434|
0001b2  428b              CMP      r3,r1                 ;284
0001b4  d3db              BCC      |L3.366|
;;;310    
;;;311      }                             // groups loop end 
;;;312    
;;;313    
;;;314    #else
;;;315    
;;;316      unsigned i, j, k, l;
;;;317      unsigned n1, n2, ia;
;;;318      q15_t xt, yt, cosVal, sinVal;
;;;319    
;;;320    
;;;321      //N = fftLen; 
;;;322      n2 = fftLen;
;;;323    
;;;324      n1 = n2;
;;;325      n2 = n2 >> 1;
;;;326      ia = 0;
;;;327    
;;;328      // loop for groups 
;;;329      for (j = 0; j < n2; j++)
;;;330      {
;;;331        cosVal = pCoef[ia * 2];
;;;332        sinVal = pCoef[(ia * 2) + 1];
;;;333        ia = ia + twidCoefModifier;
;;;334    
;;;335        // loop for butterfly 
;;;336        for (i = j; i < fftLen; i += n1)
;;;337        {
;;;338          l = i + n2;
;;;339          xt = (pSrc[2 * i] >> 1u) - (pSrc[2 * l] >> 1u);
;;;340          pSrc[2 * i] = ((pSrc[2 * i] >> 1u) + (pSrc[2 * l] >> 1u)) >> 1u;
;;;341    
;;;342          yt = (pSrc[2 * i + 1] >> 1u) - (pSrc[2 * l + 1] >> 1u);
;;;343          pSrc[2 * i + 1] =
;;;344            ((pSrc[2 * l + 1] >> 1u) + (pSrc[2 * i + 1] >> 1u)) >> 1u;
;;;345    
;;;346          pSrc[2u * l] = (((int16_t) (((q31_t) xt * cosVal) >> 16)) +
;;;347                          ((int16_t) (((q31_t) yt * sinVal) >> 16)));
;;;348    
;;;349          pSrc[2u * l + 1u] = (((int16_t) (((q31_t) yt * cosVal) >> 16)) -
;;;350                               ((int16_t) (((q31_t) xt * sinVal) >> 16)));
;;;351    
;;;352        }                           // butterfly loop end 
;;;353    
;;;354      }                             // groups loop end 
;;;355    
;;;356      twidCoefModifier = twidCoefModifier << 1u;
;;;357    
;;;358      // loop for stage 
;;;359      for (k = fftLen / 2; k > 2; k = k >> 1)
;;;360      {
;;;361        n1 = n2;
;;;362        n2 = n2 >> 1;
;;;363        ia = 0;
;;;364    
;;;365        // loop for groups 
;;;366        for (j = 0; j < n2; j++)
;;;367        {
;;;368          cosVal = pCoef[ia * 2];
;;;369          sinVal = pCoef[(ia * 2) + 1];
;;;370          ia = ia + twidCoefModifier;
;;;371    
;;;372          // loop for butterfly 
;;;373          for (i = j; i < fftLen; i += n1)
;;;374          {
;;;375            l = i + n2;
;;;376            xt = pSrc[2 * i] - pSrc[2 * l];
;;;377            pSrc[2 * i] = (pSrc[2 * i] + pSrc[2 * l]) >> 1u;
;;;378    
;;;379            yt = pSrc[2 * i + 1] - pSrc[2 * l + 1];
;;;380            pSrc[2 * i + 1] = (pSrc[2 * l + 1] + pSrc[2 * i + 1]) >> 1u;
;;;381    
;;;382            pSrc[2u * l] = (((int16_t) (((q31_t) xt * cosVal) >> 16)) +
;;;383                            ((int16_t) (((q31_t) yt * sinVal) >> 16)));
;;;384    
;;;385            pSrc[2u * l + 1u] = (((int16_t) (((q31_t) yt * cosVal) >> 16)) -
;;;386                                 ((int16_t) (((q31_t) xt * sinVal) >> 16)));
;;;387    
;;;388          }                         // butterfly loop end 
;;;389    
;;;390        }                           // groups loop end 
;;;391    
;;;392        twidCoefModifier = twidCoefModifier << 1u;
;;;393      }                             // stages loop end 
;;;394    
;;;395      n1 = n2;
;;;396      n2 = n2 >> 1;
;;;397      ia = 0;
;;;398    
;;;399      // loop for groups 
;;;400      for (j = 0; j < n2; j++)
;;;401      {
;;;402        cosVal = pCoef[ia * 2];
;;;403        sinVal = pCoef[(ia * 2) + 1];
;;;404    
;;;405        ia = ia + twidCoefModifier;
;;;406    
;;;407        // loop for butterfly 
;;;408        for (i = j; i < fftLen; i += n1)
;;;409        {
;;;410          l = i + n2;
;;;411          xt = pSrc[2 * i] - pSrc[2 * l];
;;;412          pSrc[2 * i] = (pSrc[2 * i] + pSrc[2 * l]);
;;;413    
;;;414          yt = pSrc[2 * i + 1] - pSrc[2 * l + 1];
;;;415          pSrc[2 * i + 1] = (pSrc[2 * l + 1] + pSrc[2 * i + 1]);
;;;416    
;;;417          pSrc[2u * l] = xt;
;;;418    
;;;419          pSrc[2u * l + 1u] = yt;
;;;420    
;;;421        }                           // butterfly loop end 
;;;422    
;;;423      }                             // groups loop end 
;;;424    
;;;425      twidCoefModifier = twidCoefModifier << 1u;
;;;426    
;;;427    #endif //             #ifndef ARM_MATH_CM0_FAMILY
;;;428    
;;;429    }
0001b6  e8bd8fff          POP      {r0-r11,pc}
;;;430    
                          ENDP


;*** Start embedded assembler ***

#line 1 "..\\..\\SRC\\CMSIS_DSP_4_5\\src\\TransformFunctions\\arm_cfft_radix2_q15.c"
	AREA ||.rev16_text||, CODE
	THUMB
	EXPORT |__asm___21_arm_cfft_radix2_q15_c_517ad710____REV16|
#line 129 "..\\..\\SRC\\CMSIS_DSP_4_5\\inc\\core_cmInstr.h"
|__asm___21_arm_cfft_radix2_q15_c_517ad710____REV16| PROC
#line 130

 rev16 r0, r0
 bx lr
	ENDP
	AREA ||.revsh_text||, CODE
	THUMB
	EXPORT |__asm___21_arm_cfft_radix2_q15_c_517ad710____REVSH|
#line 144
|__asm___21_arm_cfft_radix2_q15_c_517ad710____REVSH| PROC
#line 145

 revsh r0, r0
 bx lr
	ENDP
	AREA ||.rrx_text||, CODE
	THUMB
	EXPORT |__asm___21_arm_cfft_radix2_q15_c_517ad710____RRX|
#line 300
|__asm___21_arm_cfft_radix2_q15_c_517ad710____RRX| PROC
#line 301

 rrx r0, r0
 bx lr
	ENDP

;*** End   embedded assembler ***
